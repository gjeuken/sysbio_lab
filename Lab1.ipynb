{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Differential Expression analysis\n",
    "\n",
    "## About this lab\n",
    "\n",
    "On this lab, we will try to understand the underlying mechanisms and concepts behind differential expression analysis an multiple hypothesis testing. You will be asked to reflect on some core concepts of the methods and to write down your interpretations. It is important that you understand what you are doing, so toghtfull answers are expected. \n",
    "\n",
    "To successfully complete the lab you have to answer all questions and submit them in **PDF format** in Canvas. You can, and should, discuss with your classmates.\n",
    "\n",
    "You will also be provided with some optional bonus questions that involve a little more research and programing on your part, but succesful completion of those will award you points in the final examination.\n",
    "\n",
    "Let's begin! As in every notebook, we first begin by importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, interact_manual\n",
    "from ipywidgets import IntSlider, FloatSlider, Dropdown, Text\n",
    "\n",
    "interact_gen=interact_manual.options(manual_name=\"Generate data\")\n",
    "interact_plot=interact_manual.options(manual_name=\"Plot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Differential expression analysis, an intuition\n",
    "\n",
    "As you have learned, differential expression analysis trys to answer the following question: Is there any **significant** difference between the expression of two (or more) different conditions?\n",
    "\n",
    "Troghout this lab we will be exploring the concepts using simulated data, which allows us to finelly control what we are looking at and most importantly, know the true model behind the data. Later you will be asked to explore these concepts using real life data, on which you will have to look for the effects without knowing if there is really one.\n",
    "\n",
    "Our simulated data is very basic, and corresponds to two separatelly generated sets. \n",
    "On the first the data is generated by **two separate** normal distribuitions, with the data points colored acording to which distribuition they are generated from.\n",
    "On the second set, the data is generated by a **single** normal distribuition, but with the same mean and standard deviation as the combined distribuition from the previous set, and where the points are colored at random.\n",
    "\n",
    "In the language of differential expression, the colors represent de different conditions we want to test (e.g. treated/untreated, healthy/sick, etc.). \n",
    "The second data set then represents our **null hypothesis** $H_0$, that says that there is no difference between the \"expression\" of the two conditions. \n",
    "Finally the first set then represents the **alternative hypothesis** $H_1$ that says that *there is* a difference between the two conditions.\n",
    "\n",
    "I hope the explanation of this was clear, but in case you have any questions, please ask the TA as this is fundamental for the rest of the exercise.\n",
    "\n",
    "Ok, let's try to get an intuition on differential expression fist. After executing the code bellow you will be presented with 2 plots and some sliders.\n",
    "The sliders control the parameters used for generating the samples from the two different sets, and plot the results.\n",
    "The catch here is that you do not know which plot represents data under $H_0$ and which represents data under $H_1$.\n",
    "Every time you move one of the sliders, the data is regenerated, and each of the condition is **ploted randomly in the left or right panes**.\n",
    "\n",
    "Play around with the sliders as long as you feel necessary to answer these questions.\n",
    "An explanation of what the slides control:\n",
    "* Distance: the difference between the mean of each distribuition in $H_1$\n",
    "* Dispersion: the standard deviation $\\sigma$ of those distribuitions\n",
    "* Samples: The number of samples from each distribuition\n",
    "\n",
    "\n",
    "\n",
    "### Questions\n",
    "* 1.1 What is the influence of **each** variable in your ability to distinguish between $H_0$ and $H_1$?\n",
    "* 1.2 How do the different variables interact with themselves, for the same purpose?\n",
    "* 1.3 It is easy to see that often data under $H_1$ looks like data under $H_0$, but do you think you could ever misidentify data under $H_0$ as data under $H_1$?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(distance,dispersion, n_points):\n",
    "    dispersion = [[dispersion,0],[0,dispersion]]\n",
    "    cond1 = np.random.multivariate_normal([0,0], dispersion, n_points)\n",
    "    cond2 = np.random.multivariate_normal([distance,0], dispersion, n_points)\n",
    "    data1 = pd.DataFrame(cond1, columns=['x','y'])\n",
    "    data1['Condition'] = 1\n",
    "    data2 = pd.DataFrame(cond2, columns=['x','y'])\n",
    "    data2['Condition'] = 2\n",
    "    data = pd.concat([data1,data2])\n",
    "    return data\n",
    "\n",
    "def generate_h0(distance,dispersion, n_points):\n",
    "    dispersion = [[dispersion + (distance/2)**2,0],[0,dispersion]]\n",
    "    cond1 = np.random.multivariate_normal([distance/2,0], dispersion, n_points)\n",
    "    cond2 = np.random.multivariate_normal([distance/2,0], dispersion, n_points)\n",
    "    data1 = pd.DataFrame(cond1, columns=['x','y'])\n",
    "    data1['Condition'] = 1\n",
    "    data2 = pd.DataFrame(cond2, columns=['x','y'])\n",
    "    data2['Condition'] = 2\n",
    "    data = pd.concat([data1,data2])\n",
    "    return data\n",
    "\n",
    "def plot_random(data,data_s):\n",
    "    f, ax = plt.subplots(1, 2)\n",
    "    r1 = np.random.permutation(2)\n",
    "    colors = np.random.permutation(['red','blue']).tolist()\n",
    "    sns.scatterplot(x='x', y='y', data=data, hue = 'Condition', palette=colors, ax = ax[r1[0]], legend  = False)\n",
    "    sns.scatterplot(x='x', y='y', data=data_s, hue = 'Condition', palette=colors, ax = ax[r1[1]], legend = False)\n",
    "\n",
    "def dist_plot(Distance,Dispersion,Samples):\n",
    "    plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "    data = generate_data(Distance,Dispersion, Samples)\n",
    "    data_s = generate_h0(Distance,Dispersion, Samples)\n",
    "    plot_random(data,data_s)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(dist_plot, Distance = FloatSlider(min=0,max=10,value=1, continuous_update=False), Dispersion = FloatSlider(min=0,max=100,value=1, continuous_update=False), Samples=IntSlider(min=5,max=500, continuous_update=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 The t-test\n",
    "\n",
    "Now that you have a feel for what differential expression tries to achieve, and some of the obstacles on the way of doing that, lets introduce a statistical test to help us. \n",
    "We will use the **t-test**, which will give us p-value to assist us in answering the question.\n",
    "\n",
    "(As a technicality, you may have realized that the samples only differ on the $x$ axis, so we are only performing the test on that dimension)\n",
    "\n",
    "The setup here is nearly the same as above, just now you will be presented with the p-value resulting from the t-test as the title for each plot (rounded to 5 digits). Again, you should play around with the sliders and answer the following questions:\n",
    "\n",
    "### Questions\n",
    "* 2.1 Look up the Student's t-test on your favourite online enciclopedia. What are the assumptions this test makes about the data? Do this assumptions hold here?\n",
    "* 2.2 The t-test gives us a p-value. How do you interpret this value on this setup?\n",
    "* 2.3 Does the p-value confirm your intuitions from the previous part? How would you augment your previous answers (1.1 - 1.3) on that light?\n",
    "* 2.4 Our initial question was \"is there any signigicant difference between the two cases\". As an answer, it is usual to reject $H_0$ for p-values lower than 0.05. Pick a very small distance between both distributions and see if you could make it significant using the other sliders, specially the sample size, and then comment on the relations of statistical significance and biological significance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_random_ttest(data,data_s):\n",
    "    plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "    cond1 = data[data['Condition'] == 1]\n",
    "    cond2 = data[data['Condition'] == 2]\n",
    "    cond1_s = data_s[data_s['Condition'] == 1]\n",
    "    cond2_s = data_s[data_s['Condition'] == 2]\n",
    "    ttestp = sp.stats.ttest_ind(cond1, cond2).pvalue[0]\n",
    "    ttestp_s= sp.stats.ttest_ind(cond1_s, cond2_s).pvalue[0]\n",
    "    f, ax = plt.subplots(1, 2)\n",
    "    r1 = np.random.permutation(2)\n",
    "    colors = np.random.permutation(['red','blue']).tolist()\n",
    "    sns.scatterplot(x='x', y='y', data=data, hue = 'Condition', palette=colors, ax = ax[r1[0]], legend  = False)\n",
    "    ax[r1[0]].set_title('p = ' + str(np.round(ttestp, 5)), fontsize=24)\n",
    "    sns.scatterplot(x='x', y='y', data=data_s, hue = 'Condition', palette=colors, ax = ax[r1[1]], legend = False)\n",
    "    ax[r1[1]].set_title('p = ' + str(np.round(ttestp_s,5)), fontsize=24)\n",
    "    \n",
    "\n",
    "def dist_plot_ttest(Distance,Dispersion,Samples):\n",
    "    plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "    data = generate_data(Distance,Dispersion, Samples)\n",
    "    data_s = generate_h0(Distance,Dispersion, Samples)\n",
    "    plot_random_ttest(data,data_s)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(dist_plot_ttest, Distance = FloatSlider(min=0,max=10,value=1, continuous_update=False), Dispersion = FloatSlider(min=0,max=100,value=1, continuous_update=False), Samples=IntSlider(min=5,max=500, continuous_update=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise, differential gene expression analysis with TCGA data\n",
    "\n",
    "Now it is time to test all this with real data. Below we will load TCGA data on breast cancer, both clinical and gene expression data taken from the tumors.\n",
    "\n",
    "The code below loads the files data and plots the result (including p-value from the t-test. All you need to do is input the name of the gene you want to test (using HUGO nomenclature), as well how you want to separate the groups of patients.\n",
    "\n",
    "To find valid separations, you will have to look at the original file *data_clinical_patient.txt*. Remember that the input has to be exactly present in the file, and is case sensitive.\n",
    "\n",
    "Questions: \n",
    "* Is gene expression data compatible with the assumptions of the t-test? If not, how to go around it?\n",
    "* Perform the test on some (at least 5) genes that you know the function of, use **relevant** clinical conditions to sepatate the groups, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_data = pd.read_csv('data/data_clinical_patient.txt', sep ='\\t', index_col=0)\n",
    "clinical_data = clinical_data.iloc[4:,:]\n",
    "expression_data = pd.read_csv('data/data_expression_median.txt', sep ='\\t', index_col=0)\n",
    "expression_data = expression_data.T.iloc[1:,:]\n",
    "expression_data.index = list(map(lambda x: x[:-3], expression_data.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gene_ttest(clinical_df, expression_df, gene, separator, cond1, cond2):\n",
    "    try:\n",
    "        expression = expression_df[gene]\n",
    "    except:\n",
    "        print('Gene not found in data')\n",
    "    try:\n",
    "        group1 = clinical_df[separator] == cond1\n",
    "        index1 = clinical_df[group1].index\n",
    "        group2 = clinical_df[separator] == cond2\n",
    "        index2 = clinical_df[group2].index\n",
    "    except:\n",
    "        print('Clinical condition wrong')\n",
    "    expression1 = expression[index1].dropna()\n",
    "    expression2 = expression[index2].dropna()\n",
    "    cond = np.append(np.repeat('Group_1',len(expression1)),(np.repeat('Group_2',len(expression2))))\n",
    "    comb_expression = np.append(expression1.values, expression2.values)\n",
    "    plot_data = pd.DataFrame([comb_expression,cond]).T\n",
    "    plot_data.columns = ['Expression', 'Condition']\n",
    "    plot_data['Expression'] = plot_data['Expression'].astype(float)\n",
    "    p_val = sp.stats.ttest_ind(expression1, expression2).pvalue\n",
    "    plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "    sns.set(font_scale=2)\n",
    "    sns.violinplot(x='Expression', y='Condition', data=plot_data)\n",
    "    plt.title(\"p = \" + str(np.round(p_val, 5)))\n",
    "\n",
    "\n",
    "def interact_gene_ttest(Gene, Criteria, Group_1, Group_2):\n",
    "    gene_ttest(clinical_data, expression_data, Gene, Criteria, Group_1, Group_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact_plot(interact_gene_ttest, Gene = Text('BRCA1'), Criteria=Text('Overall Survival Status'), Group_1 = Text('LIVING'), Group_2=Text( 'DECEASED'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Multiple hypothesis testing\n",
    "\n",
    "So far we have been asking the question for each gene and answering it with a p-value from our statistical test.\n",
    "However, with the rich datasets generated from high-throughput experiments, we usually want to ask several different question, and we thus move to the world of multiple hypothesis testing, where the p-value is loses some of its usefulness because it leads to high **family-wise error rate**.\n",
    "\n",
    "We will here use the same data generation scheme as before, but done many times over for each $H_0$ and $H_1$. This takes much more time, so you will have the option of generating the data once and visualizing it in multiple ways. \n",
    "\n",
    "A good way visualizing how a statistical test behaves with multiple hypothesis is to visualize the distribuition of the p-values it generates, and we will explore why in the questions bellow.\n",
    "\n",
    "Bellow you will be able to generate data and visualize it using a histogram. Play around with it a while, use your best discretion on how many bins to use for the histogram, and answer the questions bellow.\n",
    "**Obs:** if you regenerate data, the plot will not automatically redraw, and will only do so when you change one of the sliders.\n",
    "\n",
    "New sliders:\n",
    "* Tests: the number of times the data is generated and the t-test performed under each $H$\n",
    "* Bins: the number of bins in the histogram\n",
    "\n",
    "\n",
    "## Questions\n",
    "* 3.1 When we say \"multiple hypothesis\", which are the hypothesis we are refering to?\n",
    "* 3.2 Explain with your own words how we can have high **family-wise error rate** even when using very strict p-values.\n",
    "* 3.3 Do you think it is easier to indentify $H_0$ and $H_1$ in this setup? Why do you think that is the case?\n",
    "* 3.4 Comment on the distribuition of p-values under $H_0$, its shape and how it changes from different realizations and how each parameter affects the distribuition.\n",
    "* 3.5 Take one realization of your data under $H_0$ and roughly count how many p-values under 0.05 you have. Is this expected? Comment also in context of your answer to question 1.3.\n",
    "* 3.6 Comment on the distribuition of p-values under $H_1$, its shape and how it changes from different realizations and how each parameter affects the distribuition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_tests(distance, dispersion, n_points, n_tests_h0, n_tests_h1):\n",
    "    h0_stats = []\n",
    "    for i in range(n_tests_h0):\n",
    "        data_h0 = generate_h0(distance,dispersion, n_points)\n",
    "        cond1_s = data_h0[data_h0['Condition'] == 1]\n",
    "        cond2_s = data_h0[data_h0['Condition'] == 2]\n",
    "        ttestp_s= sp.stats.ttest_ind(cond1_s, cond2_s).pvalue[0]\n",
    "        h0_stats.append(ttestp_s)\n",
    "\n",
    "    h1_stats = []\n",
    "    for i in range(n_tests_h1):\n",
    "        data = generate_data(distance,dispersion, n_points)\n",
    "        cond1 = data[data['Condition'] == 1]\n",
    "        cond2 = data[data['Condition'] == 2]\n",
    "        ttestp = sp.stats.ttest_ind(cond1, cond2).pvalue[0]\n",
    "        h1_stats.append(ttestp)\n",
    "        \n",
    "    return h0_stats, h1_stats\n",
    "\n",
    "def plot_hist(h0_stats, h1_stats, bins):\n",
    "    plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "    f, ax = plt.subplots(1, 2)\n",
    "    sns.distplot(h0_stats, bins = bins, ax = ax[0], kde=False, hist_kws={\"range\": [0,1]})\n",
    "    sns.distplot(h1_stats, bins = bins, ax = ax[1], kde=False, hist_kws={\"range\": [0,1]})\n",
    "    ax[0].set_title('H0')\n",
    "    ax[0].set_xlim([0,1])\n",
    "    ax[1].set_title('H1')\n",
    "    ax[1].set_xlim([0,1])\n",
    "    plt.show()\n",
    "    \n",
    "def interactive_generate(Distance, Dispersion, Samples, Tests):\n",
    "    global G_h0_results, G_h1_results\n",
    "    G_h0_results, G_h1_results = multiple_tests(Distance,Dispersion, Samples, Tests, Tests)\n",
    "    \n",
    "def interactive_double_hist(Bins):\n",
    "    plot_hist(G_h0_results, G_h1_results, Bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "interactive_generate(1, 1, 3, 100)\n",
    "interact_gen(interactive_generate, Distance = FloatSlider(min=0.0,max=10.0,value=1), Dispersion = FloatSlider(min=1.0,max=100.0,value=1), Samples = IntSlider(min=5,max=100), Tests = IntSlider(min=5,max=1000,value=100))\n",
    "interact(interactive_double_hist, Bins=IntSlider(min=10,max=50, step = 10, continuous_update=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Calculating FDR\n",
    "\n",
    "While we can, in this context, analyze both the data generated under $H_0$ and $H_1$ separatelly, in reality they are often mixed together and we use the statistical test precicely to **tell if the data comes from $H_0$ or not**.\n",
    "\n",
    "As you have seen in the exercises above, given enough tests, you will almost always hae instances where you reject the null hypothesis when it is true no matter which treshold of significance you choose. In this context, we call this errors **false discoveries**.\n",
    "The false discovery rate (FDR), then, is the rate on which these errors occur.\n",
    "\n",
    "On the next plot, you will see a **stacked histogram** on the left, showing the distribuition of p-values of both $H$ visualized together, and you will see a red vertical line that shows your signigicance threshold (left of the line = significant).\n",
    "On the right you have all the p-values ranker from lowest on hte top-left corner to highest on the lower-righ, and colored by which $H$ it originated from, with the shaded area representing those below the threshold.\n",
    "\n",
    "By moving the treshold slider, you will select on which tests you will reject the null, or in the context of differential expression, the data you believe to be *expressed diferentially* between conditions, and that will contain data that is both **truly not coming from $H_0$** and those that were **incorrectly rejected**.\n",
    "\n",
    "In our very special case here, we know from before which data comes from $H_0$ and from $H_1$, so we can calculate the FDR exactly, and that will be shown on top of the pane on the right.\n",
    "\n",
    "New sliders:\n",
    "* H_ratio: the ratio of tests performed under each $H$, calculated as $H_0/H_1$\n",
    "* Threshold: p-value threshold for rejecting $H_0$\n",
    "\n",
    "### Questions\n",
    "\n",
    "* 4.1 What relations do you see between the FDR and each of the sliders. You may refer to the answers you gave on previous questions if you wish.\n",
    "* 4.2 How does the FDR relate to the shape of the distribuition of p-values of $H_0$ and $H_1$?\n",
    "* 4.3 It is usual to think that a lower p-value threshold will lead to a lower FDR. Is this always true?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist_comb(h0_stats, h1_stats, bins, threshold):\n",
    "    plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "    f, ax = plt.subplots(1, 2)\n",
    "    ax[0].hist([h0_stats, h1_stats], bins = bins, stacked = True)\n",
    "    ax[0].vlines(threshold, 0, ax[0].get_ylim()[1], color='r', linestyles = 'dashed')\n",
    "    stats = pd.DataFrame(h1_stats + h0_stats, columns = ['p'])\n",
    "    stats['h'] = np.repeat(1,len(h1_stats)).tolist() + np.repeat(0,len(h0_stats)).tolist()\n",
    "    stats['good'] = (stats['p'] <= threshold)*1\n",
    "    discoveries = stats.loc[stats['p'] <= threshold]\n",
    "    fdr_true = 1 - sum(discoveries['h'])/len(discoveries['h'])\n",
    "    stats = stats.sort_values('p')\n",
    "    stack1 = stats['h']\n",
    "    stack2 = stats['good']\n",
    "    side = np.ceil(np.sqrt(len(stack1))).astype(int)\n",
    "    pad1 = np.zeros(side*side)+9\n",
    "    pad2 = np.zeros(side*side)+9\n",
    "    pad1[:len(stack1)]=stack1\n",
    "    pad2[:len(stack1)]=stack2 * 5\n",
    "    ax[1].imshow(pad1.reshape(side,side), cmap = 'Set1')\n",
    "    ax[1].imshow(pad2.reshape(side,side), cmap = 'Set1', alpha = 0.4)\n",
    "    ax[1].set_title('FDR: ' + str(np.round(fdr_true, 3)), fontsize=24)\n",
    "    plt.show()\n",
    "    \n",
    "def interactive_generate_n(Distance, Dispersion, Samples, Tests, H_Ratio):\n",
    "    global G_h0_results_n, G_h1_results_n\n",
    "    r = H_Ratio\n",
    "    n_tests_h0 = np.round(r*Tests*2).astype(int)\n",
    "    n_tests_h1 = np.round((1-r)*Tests*2).astype(int)\n",
    "    G_h0_results_n, G_h1_results_n = multiple_tests(Distance,Dispersion, Samples, n_tests_h0, n_tests_h1)\n",
    "\n",
    "def interactive_plot_hist_comb(Bins, Threshold):\n",
    "    plot_hist_comb(G_h0_results_n, G_h1_results_n, Bins, Threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_generate_n(1, 10, 30, 100, 0.5)\n",
    "interact_gen(interactive_generate_n, Distance = FloatSlider(min=0.0,max=10.0,value=1), Dispersion = FloatSlider(min=0.0,max=100.0,value=1), Samples = IntSlider(min=5,max=100), Tests = IntSlider(min=5,max=1000,value=100), H_Ratio = FloatSlider(min=0,max=1, step = 0.01, value = 0.5, continuous_update=False))\n",
    "interact(interactive_plot_hist_comb, Threshold = FloatSlider(min=0,max=0.5, step = 0.01,value=0.05, continuous_update=False), Bins=IntSlider(min=10,max=100, value=20, step = 10, continuous_update=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Estimating the FDR, using $\\pi_0$\n",
    "\n",
    "You probably realized by now that the p-values under $H_0$ follow a uniform distribuition. This comes from the very definition of p-values itself (!), more on why on the bonus exercise. Therefore a very good way to see if your statistical test isn't testing for the wrong thing, is to seee if the distribuition of p-values from that test under $H_0$ follows those characteristics.\n",
    "\n",
    "Knowing that fact, if we know the number of hypothesis coming from $H_0$, we can estimate the FDR very accuratelly. Unfortunatelly, that is never the case, and we have to also estimate this number.\n",
    "We do so by estimating the proportion of data under $H_0$ from the total number of test we made, and we call this proportion $\\pi_0$.\n",
    "\n",
    "Below, you will have the chance to estimate $\\pi_0$ and then see if your estimation is correct.\n",
    "Everytime you generate new data, the true $\\pi_0$ will be selected at random from the range $[0,1]$.\n",
    "See if you can find a good way to estimate it, and then aswer some questions.\n",
    "\n",
    "New sliders:\n",
    "* Pi0: Your estimative for $\\pi_0$, used to estimate the FDR\n",
    "* Separate: Separate or not $H_0$ and $H_1$ by color\n",
    "\n",
    "## Questions\n",
    "* 5.1 Describe two ways you came with to estimate $\\pi_0$, when it works and when it doesn't work.\n",
    "* 5.2 Is it easier to estimate low or high $\\pi_0$? Why?\n",
    "* 5.3 What does it mean to set $\\pi_0$ to 1. Can we do this and still get reasonable results? Why? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_hist_pi0(h0_stats, h1_stats, bins, threshold, pi0, sep):\n",
    "    plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "    stats = pd.DataFrame(h1_stats + h0_stats, columns = ['p'])\n",
    "    stats['h'] = np.repeat(1,len(h1_stats)).tolist() + np.repeat(0,len(h0_stats)).tolist()\n",
    "    stats = stats.loc[stats['p'] <= threshold]\n",
    "    fdr_true = 1 - sum(stats['h'])/len(stats['h'])\n",
    "    m = len(h0_stats + h1_stats)\n",
    "    fdr_est = (pi0*m*threshold)/len(stats['h'])\n",
    "    h = pi0*m/bins\n",
    "    if sep:\n",
    "        plt.hist([h0_stats, h1_stats], bins = bins, stacked = True, color = ['tab:blue', 'tab:orange'])\n",
    "        plt.title('Estimated FDR: ' + str(np.round(fdr_est, 3)) + ',   True FDR: ' + str(np.round(fdr_true, 3)), fontsize=24)\n",
    "    else:\n",
    "        plt.hist([h0_stats, h1_stats], bins = bins, stacked = True, color = ['tab:blue', 'tab:blue'])\n",
    "        plt.title('Estimated FDR: ' + str(np.round(fdr_est, 3)), fontsize=24)\n",
    "    plt.vlines(threshold, 0, plt.gca().get_ylim()[1], color='r', linestyles = 'dashed')\n",
    "    plt.hlines(h, 0, 1, color='black', linestyles = 'dashed', linewidth=3)\n",
    "    plt.show()\n",
    "    \n",
    "def interactive_plot_hist_pi0(Bins, Threshold, Pi0, Separate):\n",
    "    plot_hist_pi0(G_h0_results_pi0, G_h1_results_pi0, Bins, Threshold, Pi0, Separate)\n",
    "    \n",
    "def interactive_generate_n_rand(Distance, Dispersion, Samples, Tests):\n",
    "    global G_h0_results_pi0, G_h1_results_pi0\n",
    "    r = np.random.uniform(0,1)\n",
    "    n_tests_h0 = np.round(r*Tests*2).astype(int)\n",
    "    n_tests_h1 = np.round((1-r)*Tests*2).astype(int)\n",
    "    G_h0_results_pi0, G_h1_results_pi0 = multiple_tests(Distance,Dispersion, Samples, n_tests_h0, n_tests_h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_generate_n_rand(1, 10, 30, 100)\n",
    "interact_gen(interactive_generate_n_rand, Distance = FloatSlider(min=0.0,max=10.0,value=1), Dispersion = FloatSlider(min=0.0,max=100.0,value=1), Samples = IntSlider(min=5,max=100,value=10), Tests = IntSlider(min=5,max=1000,value=100))\n",
    "interact(interactive_plot_hist_pi0, Threshold = FloatSlider(min=0.01,max=0.5,value=0.05, step = 0.01, continuous_update=False), Bins=IntSlider(min=10,max=100, step = 10,value=20, continuous_update=False), Pi0 = FloatSlider(min=0,max=1, step = 0.01, continuous_update=False), Separate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Volcano plot (?), q-value (?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus exercises\n",
    "\n",
    "## P-value in depth\n",
    "* Start from the definition of p-value and prove that it's distribuition should be uniform under $\\pi_0$.\n",
    "\n",
    "Use the part of the code in this notebook that generated data from two distribuitions, but after the data is generated, reassing the conditions at random, so that the conditions are no longer associated with each of the distribuitions.\n",
    "* You will do this multiple times and perform a t-test on the conditions as before, but before doing that, how do you think the distribuition of p-values will be? Why?\n",
    "* Perform the t-test for a suitable number of times in different iterations of the data, and show it's ditribution.\n",
    "* Does it confirm what you expected? If not, what do you think happened?\n",
    "* Given the answer to your first question, how would you go around this?\n",
    "\n",
    "## Anova\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## $\\pi_0$ estimation from *Storey et al*\n",
    "\n",
    "* Read through [Storey et al](https://www.pnas.org/content/100/16/9440) and it's references if needed.\n",
    "* Explain in your own words, their proposed algoritm for estimating $\\pi_0$.\n",
    "* Explain why the parameter $\\lambda$ is important and the optimi way of choosing it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
